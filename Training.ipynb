{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Choosing and checking our GPU used."
      ],
      "metadata": {
        "id": "4LeAnH-v4RDt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GT1z3KU36AD",
        "outputId": "355d7934-69ce-4b24-abc4-d9185ecf7cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUtbiUHh8pYS",
        "outputId": "0e8f12d1-751e-432f-ac33-2e8dead6b9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUqpN_A66BZJ",
        "outputId": "d609c50c-1486-4bb3-a64b-eefe65c378b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.170-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.170-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.170 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8s.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtJu99BJubN4",
        "outputId": "eb705211-3070-4f4b-8e38-2e7635461616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.5M/21.5M [00:00<00:00, 526MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Albumentations"
      ],
      "metadata": {
        "id": "BIelFuhXRHCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define simple transforms for smoke/fire detection\n",
        "def get_simple_transforms():\n",
        "    return A.Compose([\n",
        "        # Essential color transforms for smoke/fire\n",
        "        A.RandomBrightnessContrast(\n",
        "            brightness_limit=0.2,\n",
        "            contrast_limit=0.2,\n",
        "            p=0.6\n",
        "        ),\n",
        "        A.HueSaturationValue(\n",
        "            hue_shift_limit=10,\n",
        "            sat_shift_limit=20,\n",
        "            val_shift_limit=10,\n",
        "            p=0.5\n",
        "        ),\n",
        "\n",
        "        # Blur for smoke simulation\n",
        "        A.GaussianBlur(blur_limit=(3, 5), p=0.3),\n",
        "\n",
        "        # Basic geometric\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Rotate(limit=10, p=0.3),\n",
        "\n",
        "        # Resize to ensure consistent input size\n",
        "        A.Resize(640, 640, p=1.0),\n",
        "\n",
        "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
        "\n",
        "def augment_single_image(image_path, label_path, output_dir, transform, num_augmentations=2):\n",
        "    \"\"\"\n",
        "    Augment a single YOLO format image and label pair\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read image\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"Could not read image: {image_path}\")\n",
        "            return\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Read YOLO format labels\n",
        "        bboxes = []\n",
        "        class_labels = []\n",
        "\n",
        "        if os.path.exists(label_path) and os.path.getsize(label_path) > 0:\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 5:\n",
        "                    class_id = int(parts[0])\n",
        "                    x_center, y_center, width, height = map(float, parts[1:5])\n",
        "                    bboxes.append([x_center, y_center, width, height])\n",
        "                    class_labels.append(class_id)\n",
        "\n",
        "        # If no bboxes, still augment the image (background images)\n",
        "        if not bboxes:\n",
        "            bboxes = []\n",
        "            class_labels = []\n",
        "\n",
        "        # Create augmented versions\n",
        "        base_name = Path(image_path).stem\n",
        "\n",
        "        for i in range(num_augmentations):\n",
        "            try:\n",
        "                transformed = transform(\n",
        "                    image=image,\n",
        "                    bboxes=bboxes,\n",
        "                    class_labels=class_labels\n",
        "                )\n",
        "\n",
        "                aug_image = transformed['image']\n",
        "                aug_bboxes = transformed['bboxes']\n",
        "                aug_labels = transformed['class_labels']\n",
        "\n",
        "                # Save augmented image\n",
        "                aug_image_path = os.path.join(output_dir, 'images', f\"{base_name}_aug_{i}.jpg\")\n",
        "                os.makedirs(os.path.dirname(aug_image_path), exist_ok=True)\n",
        "                aug_image_bgr = cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR)\n",
        "                cv2.imwrite(aug_image_path, aug_image_bgr)\n",
        "\n",
        "                # Save augmented labels\n",
        "                aug_label_path = os.path.join(output_dir, 'labels', f\"{base_name}_aug_{i}.txt\")\n",
        "                os.makedirs(os.path.dirname(aug_label_path), exist_ok=True)\n",
        "\n",
        "                with open(aug_label_path, 'w') as f:\n",
        "                    for bbox, label in zip(aug_bboxes, aug_labels):\n",
        "                        f.write(f\"{label} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\\n\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error creating augmentation {i} for {image_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "def augment_dataset(original_dataset_path, augmented_dataset_path, num_augmentations=2):\n",
        "    \"\"\"\n",
        "    Augment entire YOLO dataset\n",
        "    \"\"\"\n",
        "    print(\"Starting dataset augmentation...\")\n",
        "\n",
        "    # Create output directories\n",
        "    os.makedirs(augmented_dataset_path, exist_ok=True)\n",
        "\n",
        "    # Get transform\n",
        "    transform = get_simple_transforms()\n",
        "\n",
        "    # Process each split (train, val, test)\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        print(f\"\\nProcessing {split} split...\")\n",
        "\n",
        "        # Create directories\n",
        "        split_images_dir = os.path.join(augmented_dataset_path, split, 'images')\n",
        "        split_labels_dir = os.path.join(augmented_dataset_path, split, 'labels')\n",
        "        os.makedirs(split_images_dir, exist_ok=True)\n",
        "        os.makedirs(split_labels_dir, exist_ok=True)\n",
        "\n",
        "        # Source directories\n",
        "        src_images_dir = os.path.join(original_dataset_path, split, 'images')\n",
        "        src_labels_dir = os.path.join(original_dataset_path, split, 'labels')\n",
        "\n",
        "        if not os.path.exists(src_images_dir):\n",
        "            print(f\"Source directory not found: {src_images_dir}\")\n",
        "            continue\n",
        "\n",
        "        # Get all image files\n",
        "        image_files = []\n",
        "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
        "            image_files.extend(Path(src_images_dir).glob(ext))\n",
        "\n",
        "        print(f\"Found {len(image_files)} images in {split}\")\n",
        "\n",
        "        # First, copy original files\n",
        "        print(f\"Copying original {split} files...\")\n",
        "        for img_path in tqdm(image_files):\n",
        "            # Copy image\n",
        "            dst_img = os.path.join(split_images_dir, img_path.name)\n",
        "            shutil.copy2(img_path, dst_img)\n",
        "\n",
        "            # Copy label if exists\n",
        "            label_path = os.path.join(src_labels_dir, img_path.stem + '.txt')\n",
        "            if os.path.exists(label_path):\n",
        "                dst_label = os.path.join(split_labels_dir, img_path.stem + '.txt')\n",
        "                shutil.copy2(label_path, dst_label)\n",
        "            else:\n",
        "                # Create empty label file\n",
        "                dst_label = os.path.join(split_labels_dir, img_path.stem + '.txt')\n",
        "                open(dst_label, 'w').close()\n",
        "\n",
        "        # Then create augmented versions (only for training set)\n",
        "        if split == 'train':\n",
        "            print(f\"Creating {num_augmentations} augmentations per training image...\")\n",
        "            for img_path in tqdm(image_files):\n",
        "                label_path = os.path.join(src_labels_dir, img_path.stem + '.txt')\n",
        "                augment_single_image(\n",
        "                    str(img_path),\n",
        "                    label_path,\n",
        "                    os.path.join(augmented_dataset_path, split),\n",
        "                    transform,\n",
        "                    num_augmentations\n",
        "                )\n",
        "\n",
        "    print(\"Dataset augmentation completed!\")\n",
        "\n",
        "def create_augmented_data_yaml(original_yaml_path, augmented_dataset_path, output_yaml_path):\n",
        "    \"\"\"\n",
        "    Create data.yaml file for augmented dataset\n",
        "    \"\"\"\n",
        "    # Read original yaml\n",
        "    with open(original_yaml_path, 'r') as f:\n",
        "        data = yaml.safe_load(f)\n",
        "\n",
        "    # Update paths\n",
        "    data['train'] = os.path.join(augmented_dataset_path, 'train', 'images')\n",
        "    data['val'] = os.path.join(augmented_dataset_path, 'val', 'images')\n",
        "    data['test'] = os.path.join(augmented_dataset_path,'test', 'images')\n",
        "\n",
        "    # Save new yaml\n",
        "    with open(output_yaml_path, 'w') as f:\n",
        "        yaml.dump(data, f, default_flow_style=False)\n",
        "\n",
        "    print(f\"Created augmented data.yaml at: {output_yaml_path}\")\n",
        "    return output_yaml_path\n",
        "\n",
        "def train_with_albumentations():\n",
        "    \"\"\"\n",
        "    Complete training pipeline with Albumentations\n",
        "    \"\"\"\n",
        "    # Paths\n",
        "    original_dataset = \"/content/dataset\"\n",
        "    augmented_dataset = \"/content/augmented_dataset\"\n",
        "    original_yaml = \"/content/dataset/data.yaml\"\n",
        "    augmented_yaml = \"/content/augmented_dataset/data.yaml\"\n",
        "\n",
        "    print(\"=== YOLO Training with Albumentations ===\")\n",
        "    print(f\"Original dataset: {original_dataset}\")\n",
        "    print(f\"Augmented dataset: {augmented_dataset}\")\n",
        "\n",
        "    # Step 1: Create augmented dataset\n",
        "    if not os.path.exists(augmented_dataset):\n",
        "        print(\"\\nStep 1: Creating augmented dataset...\")\n",
        "        augment_dataset(original_dataset, augmented_dataset, num_augmentations=2)\n",
        "    else:\n",
        "        print(\"\\nStep 1: Augmented dataset already exists, skipping...\")\n",
        "\n",
        "    # Step 2: Create data.yaml for augmented dataset\n",
        "    print(\"\\nStep 2: Creating data.yaml for augmented dataset...\")\n",
        "    create_augmented_data_yaml(original_yaml, augmented_dataset, augmented_yaml)\n",
        "\n",
        "    # Step 3: Train baseline model (with built-in augmentations)\n",
        "    # print(\"\\nStep 3: Training baseline model with YOLO built-in augmentations...\")\n",
        "    # baseline_model = YOLO(\"yolov8s.pt\")\n",
        "\n",
        "    # baseline_results = baseline_model.train(\n",
        "    #     data=original_yaml,\n",
        "    #     epochs=200,  # Reduced for comparison\n",
        "    #     batch=32,\n",
        "    #     augment=True,  # YOLO built-in augmentations\n",
        "    #     patience=15,\n",
        "    #     name=\"baseline_builtin\",\n",
        "    #     verbose=True\n",
        "    # )\n",
        "\n",
        "    # print(f\"Baseline training completed!\")\n",
        "    # print(f\"Baseline mAP50: {baseline_results.results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n",
        "\n",
        "    # Step 4: Train with Albumentations-augmented dataset\n",
        "    print(\"\\nStep 4: Training with Albumentations-augmented dataset...\")\n",
        "    albumentations_model = YOLO(\"/content/runs/detect/baseline_builtin2/weights/best.pt\")  # Start fresh or use best baseline\n",
        "\n",
        "    albumentations_results = albumentations_model.train(\n",
        "        data=augmented_yaml,\n",
        "        epochs=200,\n",
        "        batch=32,\n",
        "        augment=False,  # Disable built-in since we pre-augmented\n",
        "        patience=15,\n",
        "        name=\"albumentations_augmented\",\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    print(f\"Albumentations training completed!\")\n",
        "    print(f\"Albumentations mAP50: {albumentations_results.results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n",
        "\n",
        "    # Step 5: Compare results\n",
        "    print(\"\\n=== RESULTS COMPARISON ===\")\n",
        "    # baseline_map = baseline_results.results_dict.get('metrics/mAP50(B)', 0)\n",
        "    albumentations_map = albumentations_results.results_dict.get('metrics/mAP50(B)', 0)\n",
        "\n",
        "    # print(f\"Baseline (YOLO built-in):     mAP50 = {baseline_map:.3f}\")\n",
        "    print(f\"Albumentations (pre-augmented): mAP50 = {albumentations_map:.3f}\")\n",
        "\n",
        "    # if albumentations_map > baseline_map:\n",
        "    #     improvement = albumentations_map - baseline_map\n",
        "    #     print(f\"âœ… Improvement: +{improvement:.3f} mAP50 ({improvement/baseline_map*100:.1f}%)\")\n",
        "    # else:\n",
        "    #     decrease = baseline_map - albumentations_map\n",
        "    #     print(f\"âŒ Decrease: -{decrease:.3f} mAP50 ({decrease/baseline_map*100:.1f}%)\")\n",
        "\n",
        "    return albumentations_results\n",
        "\n",
        "# Quick test function\n",
        "def test_transforms():\n",
        "    \"\"\"\n",
        "    Test that transforms work correctly\n",
        "    \"\"\"\n",
        "    print(\"Testing Albumentations transforms...\")\n",
        "\n",
        "    transform = get_simple_transforms()\n",
        "\n",
        "    # Create dummy data\n",
        "    dummy_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
        "    dummy_bboxes = [[0.5, 0.5, 0.2, 0.3], [0.3, 0.7, 0.1, 0.1]]  # YOLO format\n",
        "    dummy_labels = [0, 1]  # smoke, fire\n",
        "\n",
        "    try:\n",
        "        result = transform(\n",
        "            image=dummy_image,\n",
        "            bboxes=dummy_bboxes,\n",
        "            class_labels=dummy_labels\n",
        "        )\n",
        "\n",
        "        print(\"âœ… Transform test successful!\")\n",
        "        print(f\"Input image shape: {dummy_image.shape}\")\n",
        "        print(f\"Output image shape: {result['image'].shape}\")\n",
        "        print(f\"Input bboxes: {dummy_bboxes}\")\n",
        "        print(f\"Output bboxes: {result['bboxes']}\")\n",
        "        print(f\"Labels preserved: {result['class_labels']}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Transform test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # First test transforms\n",
        "    if test_transforms():\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        # Run full training pipeline\n",
        "        baseline_results, albumentations_results = train_with_albumentations()\n",
        "    else:\n",
        "        print(\"Fix transform issues before proceeding with training.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZuS_WAcASBVc",
        "outputId": "b60d55b2-cee8-4a52-c200-b2f26b1ae75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Albumentations transforms...\n",
            "âœ… Transform test successful!\n",
            "Input image shape: (480, 640, 3)\n",
            "Output image shape: (640, 640, 3)\n",
            "Input bboxes: [[0.5, 0.5, 0.2, 0.3], [0.3, 0.7, 0.1, 0.1]]\n",
            "Output bboxes: [[0.49999998435732645, 0.49999998651740485, 0.2151710023059915, 0.31782780796162585], [0.7099523981048264, 0.6809603177099683, 0.10497623033776027, 0.10903512280268457]]\n",
            "Labels preserved: [0.0, 1.0]\n",
            "\n",
            "==================================================\n",
            "=== YOLO Training with Albumentations ===\n",
            "Original dataset: /content/dataset\n",
            "Augmented dataset: /content/augmented_dataset\n",
            "\n",
            "Step 1: Augmented dataset already exists, skipping...\n",
            "\n",
            "Step 2: Creating data.yaml for augmented dataset...\n",
            "Created augmented data.yaml at: /content/augmented_dataset/data.yaml\n",
            "\n",
            "Step 4: Training with Albumentations-augmented dataset...\n",
            "New https://pypi.org/project/ultralytics/8.3.171 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.170 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/augmented_dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/runs/detect/baseline_builtin2/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=albumentations_augmented6, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/albumentations_augmented6, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "\u001b[34m\u001b[1mtrain: \u001b[0mError loading data from /content/augmented_dataset/train/images\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36mget_img_files\u001b[0;34m(self, img_path)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# self.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS])  # pathlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mim_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{self.prefix}No images found in {img_path}. {FORMATS_HELP_MSG}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: \u001b[34m\u001b[1mtrain: \u001b[0mNo images found in /content/augmented_dataset/train/images. Supported formats are:\nimages: {'heic', 'jpeg', 'tiff', 'mpo', 'webp', 'dng', 'bmp', 'jpg', 'pfm', 'png', 'tif'}\nvideos: {'avi', 'm4v', 'mp4', 'ts', 'mpeg', 'gif', 'asf', 'mkv', 'mov', 'wmv', 'mpg', 'webm'}",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3629909145.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# Run full training pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0mbaseline_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbumentations_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_with_albumentations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fix transform issues before proceeding with training.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3629909145.py\u001b[0m in \u001b[0;36mtrain_with_albumentations\u001b[0;34m()\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0malbumentations_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/runs/detect/baseline_builtin2/weights/best.pt\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Start fresh or use best baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     albumentations_results = albumentations_model.train(\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugmented_yaml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# Dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         self.train_loader = self.get_dataloader(\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL_RANK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(self, dataset_path, batch_size, rank, mode)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Mode must be 'train' or 'val', not {mode}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# init dataset *.cache only once if DDP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[1;32m     66\u001b[0m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_yolo_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mbuild_yolo_dataset\u001b[0;34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;34m\"\"\"Build and return a YOLO dataset based on configuration parameters.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLOMultiModalDataset\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmulti_modal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mYOLODataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     return dataset(\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, task, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_segments\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_keypoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Can not use both segments and keypoints.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"channels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcache_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./labels.cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction, channels)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_img_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# single_cls and include_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36mget_img_files\u001b[0;34m(self, img_path)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mim_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{self.prefix}No images found in {img_path}. {FORMATS_HELP_MSG}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.prefix}Error loading data from {img_path}\\n{HELP_URL}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfraction\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mim_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_files\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# retain a fraction of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: \u001b[34m\u001b[1mtrain: \u001b[0mError loading data from /content/augmented_dataset/train/images\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train data=\"/content/FireSmokeDataset-3/data.yaml\" model=yolov8s.pt epochs=150 batch=32 imgsz=640 optimizer=\"SGD\" lr0=0.01 momentum=0.937 weight_decay=0.0005 augment=True hsv_h=0.03 hsv_s=0.7 patience=20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNTtiSux6ZhD",
        "outputId": "291c02eb-5ed2-419a-cf2b-e30bf7770dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n",
            "100% 21.5M/21.5M [00:00<00:00, 186MB/s]\n",
            "Ultralytics 8.3.170 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/FireSmokeDataset-3/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.03, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 14.3MB/s]\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2117209  ultralytics.nn.modules.head.Detect           [3, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,761 parameters, 11,136,745 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 64.6MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1679.3Â±798.6 MB/s, size: 50.9 KB)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/FireSmokeDataset-3/train/labels... 38258 images, 1321 backgrounds, 0 corrupt: 100% 38258/38258 [00:24<00:00, 1588.86it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/FireSmokeDataset-3/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 934.8Â±401.0 MB/s, size: 45.6 KB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/FireSmokeDataset-3/valid/labels... 6068 images, 182 backgrounds, 0 corrupt: 100% 6068/6068 [00:04<00:00, 1450.28it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/FireSmokeDataset-3/valid/labels.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 150 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      1/150      6.47G      1.484      1.713      1.622         90        640: 100% 1196/1196 [02:57<00:00,  6.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:22<00:00,  4.17it/s]\n",
            "                   all       6068      12990      0.662      0.588      0.629      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      2/150      8.01G      1.353      1.321      1.486         63        640: 100% 1196/1196 [02:51<00:00,  6.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.35it/s]\n",
            "                   all       6068      12990      0.636        0.6      0.635      0.344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      3/150      8.04G      1.389      1.373      1.515         96        640: 100% 1196/1196 [02:46<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:22<00:00,  4.22it/s]\n",
            "                   all       6068      12990       0.59      0.543      0.543      0.271\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      4/150      8.06G       1.41      1.414      1.544         81        640: 100% 1196/1196 [02:46<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:22<00:00,  4.31it/s]\n",
            "                   all       6068      12990      0.654      0.616      0.643      0.341\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      5/150      8.08G      1.349       1.32      1.509         94        640: 100% 1196/1196 [02:46<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.34it/s]\n",
            "                   all       6068      12990      0.681      0.627      0.673      0.374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      6/150      8.11G      1.306      1.241      1.473         82        640: 100% 1196/1196 [02:46<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.33it/s]\n",
            "                   all       6068      12990      0.732      0.635      0.698       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      7/150      8.13G      1.279      1.207      1.455         56        640: 100% 1196/1196 [02:46<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.38it/s]\n",
            "                   all       6068      12990      0.724       0.65       0.71      0.407\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      8/150      8.16G      1.256      1.168      1.438         95        640: 100% 1196/1196 [02:47<00:00,  7.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:22<00:00,  4.31it/s]\n",
            "                   all       6068      12990      0.735      0.664      0.721       0.42\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      9/150      8.18G      1.234      1.137       1.42         78        640: 100% 1196/1196 [02:47<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.35it/s]\n",
            "                   all       6068      12990      0.732      0.678      0.735      0.429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     10/150      8.21G      1.214       1.11       1.41         84        640: 100% 1196/1196 [02:46<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.35it/s]\n",
            "                   all       6068      12990      0.755      0.692      0.751      0.446\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     11/150      8.23G      1.202      1.086      1.399         65        640: 100% 1196/1196 [02:46<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.37it/s]\n",
            "                   all       6068      12990       0.76      0.701      0.759      0.456\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     12/150      8.25G      1.185      1.064       1.39         63        640: 100% 1196/1196 [02:46<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:22<00:00,  4.31it/s]\n",
            "                   all       6068      12990      0.749        0.7      0.757      0.457\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     13/150      8.28G      1.176      1.047       1.38         64        640: 100% 1196/1196 [02:48<00:00,  7.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.36it/s]\n",
            "                   all       6068      12990      0.766      0.717       0.77      0.468\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     14/150       8.3G      1.163      1.035      1.373         98        640: 100% 1196/1196 [02:47<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.37it/s]\n",
            "                   all       6068      12990      0.767      0.706      0.765      0.467\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     15/150      8.33G      1.153      1.013      1.364        101        640: 100% 1196/1196 [02:47<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.35it/s]\n",
            "                   all       6068      12990      0.773      0.718      0.775      0.478\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     16/150      8.35G      1.147      1.006      1.358         58        640: 100% 1196/1196 [02:46<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.35it/s]\n",
            "                   all       6068      12990       0.77       0.72      0.776       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     17/150      8.38G      1.134     0.9931      1.351         92        640: 100% 1196/1196 [02:46<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.39it/s]\n",
            "                   all       6068      12990      0.787      0.725      0.783      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     18/150       8.4G      1.129     0.9754      1.343         80        640: 100% 1196/1196 [02:46<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.40it/s]\n",
            "                   all       6068      12990      0.778       0.72       0.78      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     19/150      8.43G       1.12     0.9634      1.334         84        640: 100% 1196/1196 [02:46<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.40it/s]\n",
            "                   all       6068      12990      0.787      0.727      0.786       0.49\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     20/150      8.45G      1.116     0.9531      1.333         70        640: 100% 1196/1196 [02:46<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.40it/s]\n",
            "                   all       6068      12990      0.793      0.728      0.792      0.496\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     21/150      8.47G      1.112     0.9508      1.331         92        640: 100% 1196/1196 [02:46<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.39it/s]\n",
            "                   all       6068      12990      0.791      0.725       0.79      0.496\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     22/150       8.5G      1.103     0.9345      1.323         58        640: 100% 1196/1196 [02:46<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.38it/s]\n",
            "                   all       6068      12990      0.785      0.731       0.79      0.497\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     23/150      8.52G      1.095     0.9221      1.318         88        640: 100% 1196/1196 [02:46<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.34it/s]\n",
            "                   all       6068      12990      0.791      0.729      0.791      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     24/150      8.54G      1.093     0.9196      1.315         94        640: 100% 1196/1196 [02:46<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.34it/s]\n",
            "                   all       6068      12990      0.791      0.734      0.792      0.499\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     25/150      8.57G      1.083     0.9083      1.307         91        640: 100% 1196/1196 [02:47<00:00,  7.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.40it/s]\n",
            "                   all       6068      12990       0.79      0.737      0.793      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     26/150      8.59G       1.08     0.9001      1.305         98        640: 100% 1196/1196 [02:46<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.37it/s]\n",
            "                   all       6068      12990      0.789      0.739      0.793      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     27/150      8.62G      1.075     0.8903      1.302         72        640: 100% 1196/1196 [02:47<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.35it/s]\n",
            "                   all       6068      12990      0.791       0.74      0.793      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     28/150      8.64G      1.069     0.8793      1.294         66        640: 100% 1196/1196 [02:47<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.42it/s]\n",
            "                   all       6068      12990       0.79      0.741      0.794      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     29/150      8.67G      1.065     0.8776      1.292         54        640: 100% 1196/1196 [02:47<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.38it/s]\n",
            "                   all       6068      12990      0.791       0.74      0.794      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     30/150      8.69G       1.06     0.8731       1.29         74        640: 100% 1196/1196 [02:46<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.43it/s]\n",
            "                   all       6068      12990       0.79       0.74      0.793      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     31/150      8.72G      1.053     0.8601      1.283        109        640: 100% 1196/1196 [02:47<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.41it/s]\n",
            "                   all       6068      12990      0.789      0.741      0.793      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     32/150      8.74G      1.054     0.8635      1.286         84        640: 100% 1196/1196 [02:46<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.37it/s]\n",
            "                   all       6068      12990       0.79      0.737      0.792      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     33/150      8.77G      1.045     0.8515      1.278         72        640: 100% 1196/1196 [02:46<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.44it/s]\n",
            "                   all       6068      12990      0.791      0.737      0.792      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     34/150      8.79G      1.043     0.8446      1.274         82        640: 100% 1196/1196 [02:46<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.36it/s]\n",
            "                   all       6068      12990      0.795      0.734      0.793      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     35/150      8.81G       1.04     0.8405      1.275         89        640: 100% 1196/1196 [02:47<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.44it/s]\n",
            "                   all       6068      12990      0.798      0.733      0.793      0.503\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     36/150      8.84G      1.033      0.831      1.265         83        640: 100% 1196/1196 [02:46<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.39it/s]\n",
            "                   all       6068      12990      0.798      0.732      0.793      0.503\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     37/150      8.86G      1.031     0.8307      1.266         70        640: 100% 1196/1196 [02:47<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.42it/s]\n",
            "                   all       6068      12990      0.799      0.732      0.794      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     38/150      8.89G      1.035     0.8308      1.266         72        640: 100% 1196/1196 [02:47<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.44it/s]\n",
            "                   all       6068      12990        0.8      0.732      0.794      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     39/150      8.91G      1.022     0.8176       1.26         81        640: 100% 1196/1196 [02:46<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 95/95 [00:21<00:00,  4.39it/s]\n",
            "                   all       6068      12990      0.802      0.731      0.795      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     40/150      8.93G      1.018     0.8091      1.256        178        640:  54% 649/1196 [01:30<01:15,  7.21it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpAqsaruwNpa",
        "outputId": "b0e6d791-e041-4f28-d35a-9284a6fc2d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "rf = Roboflow(api_key=\"aAbQRSqmt35Aah8o74ur\")\n",
        "project = rf.workspace(\"catargiuconstantin\").project(\"firesmokedataset\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1Uf-EfdYcIj",
        "outputId": "15ec79c6-38f7-4253-8876-310e634cae46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in FireSmokeDataset-3 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2176969/2176969 [00:26<00:00, 82842.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to FireSmokeDataset-3 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 93138/93138 [00:13<00:00, 7030.14it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/dataset.zip\"\n",
        "extract_to = \"/content/dataset\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n"
      ],
      "metadata": {
        "id": "jJF0VMX15v3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/runs /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "pzgaMZv-oTfd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}