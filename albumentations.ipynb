{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1754045592176
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipywidgets in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (7.0.0)\n",
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab_widgets~=3.0.15\n",
            "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.3.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
            "Requirement already satisfied: comm>=0.1.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ipywidgets) (8.37.0)\n",
            "Collecting widgetsnbextension~=4.0.14\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.0)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.14.0)\n",
            "Requirement already satisfied: stack_data in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
            "Requirement already satisfied: exceptiongroup in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: decorator in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: pure-eval in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
            "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.0.8\n",
            "    Uninstalling widgetsnbextension-3.0.8:\n",
            "      Successfully uninstalled widgetsnbextension-3.0.8\n",
            "  Attempting uninstall: jupyterlab_widgets\n",
            "    Found existing installation: jupyterlab_widgets 1.1.11\n",
            "    Uninstalling jupyterlab_widgets-1.1.11:\n",
            "      Successfully uninstalled jupyterlab_widgets-1.1.11\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.0.0\n",
            "    Uninstalling ipywidgets-7.0.0:\n",
            "      Successfully uninstalled ipywidgets-7.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "azureml-widgets 1.60.0 requires ipywidgets<8.0.0,>=7.0.0, but you have ipywidgets 8.1.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install -U ipywidgets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1754141391585
        }
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tempfile\n",
        "import json\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Defining transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1754141392805
        }
      },
      "outputs": [],
      "source": [
        "def get_simple_transforms():\n",
        "    return A.Compose([\n",
        "        # Essential color transforms for smoke/fire\n",
        "        A.RandomBrightnessContrast(\n",
        "            brightness_limit=0.2,\n",
        "            contrast_limit=0.2,\n",
        "            p=0.6\n",
        "        ),\n",
        "        A.HueSaturationValue(\n",
        "            hue_shift_limit=10,\n",
        "            sat_shift_limit=20,\n",
        "            val_shift_limit=10,\n",
        "            p=0.5\n",
        "        ),\n",
        "\n",
        "        # Blur for smoke simulation\n",
        "        A.GaussianBlur(blur_limit=(3, 5), p=0.3),\n",
        "\n",
        "        # Basic geometric\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Rotate(limit=10, p=0.3),\n",
        "\n",
        "        # Resize to ensure consistent input size\n",
        "        A.Resize(640, 640, p=1.0),\n",
        "\n",
        "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1754141395396
        }
      },
      "outputs": [],
      "source": [
        "def get_azure_writable_path():\n",
        "    \"\"\"\n",
        "    Get a writable path in Azure ML Studio\n",
        "    \"\"\"\n",
        "    # Try different writable locations in Azure ML\n",
        "    writable_locations = [\n",
        "        \"/tmp\",                    # Temporary directory (usually writable)\n",
        "        \"/home/azureuser\",         # User home directory\n",
        "        os.path.expanduser(\"~\"),   # Home directory expansion\n",
        "        \".\",                       # Current working directory\n",
        "        \"./temp\"                   # Local temp directory\n",
        "    ]\n",
        "    \n",
        "    for location in writable_locations:\n",
        "        try:\n",
        "            test_dir = os.path.join(location, \"test_write_permission\")\n",
        "            os.makedirs(test_dir, exist_ok=True)\n",
        "            \n",
        "            # Test write permission\n",
        "            test_file = os.path.join(test_dir, \"test.txt\")\n",
        "            with open(test_file, 'w') as f:\n",
        "                f.write(\"test\")\n",
        "            \n",
        "            # Clean up test\n",
        "            os.remove(test_file)\n",
        "            os.rmdir(test_dir)\n",
        "            \n",
        "            print(f\"✅ Found writable location: {location}\")\n",
        "            return location\n",
        "            \n",
        "        except (PermissionError, OSError) as e:\n",
        "            print(f\"❌ Cannot write to {location}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    # Fallback to temp directory\n",
        "    temp_dir = tempfile.mkdtemp()\n",
        "    print(f\"⚠️ Using temporary directory: {temp_dir}\")\n",
        "    return temp_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Augmentation of every image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1754141397901
        }
      },
      "outputs": [],
      "source": [
        "def augment_single_image(image_path, label_path, output_dir, transform, num_augmentations=2):\n",
        "    \"\"\"\n",
        "    Augment a single YOLO format image and label pair\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read image\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"Could not read image: {image_path}\")\n",
        "            return\n",
        "        \n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Read YOLO format labels\n",
        "        bboxes = []\n",
        "        class_labels = []\n",
        "        \n",
        "        if os.path.exists(label_path) and os.path.getsize(label_path) > 0:\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            \n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 5:\n",
        "                    class_id = int(parts[0])\n",
        "                    x_center, y_center, width, height = map(float, parts[1:5])\n",
        "                    bboxes.append([x_center, y_center, width, height])\n",
        "                    class_labels.append(class_id)\n",
        "        \n",
        "        # If no bboxes, still augment the image (background images)\n",
        "        if not bboxes:\n",
        "            bboxes = []\n",
        "            class_labels = []\n",
        "        \n",
        "        # Create augmented versions\n",
        "        base_name = Path(image_path).stem\n",
        "        \n",
        "        for i in range(num_augmentations):\n",
        "            try:\n",
        "                transformed = transform(\n",
        "                    image=image,\n",
        "                    bboxes=bboxes,\n",
        "                    class_labels=class_labels\n",
        "                )\n",
        "                \n",
        "                aug_image = transformed['image']\n",
        "                aug_bboxes = transformed['bboxes']\n",
        "                aug_labels = transformed['class_labels']\n",
        "                \n",
        "                # Save augmented image\n",
        "                aug_image_path = os.path.join(output_dir, 'images', f\"{base_name}_aug_{i}.jpg\")\n",
        "                os.makedirs(os.path.dirname(aug_image_path), exist_ok=True)\n",
        "                aug_image_bgr = cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR)\n",
        "                cv2.imwrite(aug_image_path, aug_image_bgr)\n",
        "                \n",
        "                # Save augmented labels\n",
        "                aug_label_path = os.path.join(output_dir, 'labels', f\"{base_name}_aug_{i}.txt\")\n",
        "                os.makedirs(os.path.dirname(aug_label_path), exist_ok=True)\n",
        "                \n",
        "                with open(aug_label_path, 'w') as f:\n",
        "                    for bbox, label in zip(aug_bboxes, aug_labels):\n",
        "                        f.write(f\"{label} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\\n\")\n",
        "                        \n",
        "            except Exception as e:\n",
        "                print(f\"Error creating augmentation {i} for {image_path}: {e}\")\n",
        "                continue\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Create augment dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1754141466858
        }
      },
      "outputs": [],
      "source": [
        "def augment_dataset(original_dataset_path, augmented_dataset_path, num_augmentations=2):\n",
        "    \"\"\"\n",
        "    Augment entire YOLO dataset\n",
        "    \"\"\"\n",
        "    print(\"Starting dataset augmentation...\")\n",
        "    print(f\"Source: {original_dataset_path}\")\n",
        "    print(f\"Target: {augmented_dataset_path}\")\n",
        "    \n",
        "    # Create output directories with error handling\n",
        "    try:\n",
        "        os.makedirs(augmented_dataset_path, exist_ok=True)\n",
        "        print(f\"✅ Created output directory: {augmented_dataset_path}\")\n",
        "    except PermissionError as e:\n",
        "        print(f\"❌ Permission error creating {augmented_dataset_path}: {e}\")\n",
        "        raise\n",
        "    \n",
        "    # Get transform\n",
        "    transform = get_simple_transforms()\n",
        "    \n",
        "    # Process each split (train, val, test)\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        print(f\"\\nProcessing {split} split...\")\n",
        "        \n",
        "        # Create directories\n",
        "        split_images_dir = os.path.join(augmented_dataset_path, split, 'images')\n",
        "        split_labels_dir = os.path.join(augmented_dataset_path, split, 'labels')\n",
        "        \n",
        "        try:\n",
        "            os.makedirs(split_images_dir, exist_ok=True)\n",
        "            os.makedirs(split_labels_dir, exist_ok=True)\n",
        "            print(f\"✅ Created {split} directories\")\n",
        "        except PermissionError as e:\n",
        "            print(f\"❌ Permission error creating {split} directories: {e}\")\n",
        "            continue\n",
        "        \n",
        "        # Source directories\n",
        "        src_images_dir = os.path.join(original_dataset_path, split, 'images')\n",
        "        src_labels_dir = os.path.join(original_dataset_path, split, 'labels')\n",
        "        \n",
        "        if not os.path.exists(src_images_dir):\n",
        "            print(f\"❌ Source directory not found: {src_images_dir}\")\n",
        "            continue\n",
        "        \n",
        "        # Get all image files\n",
        "        image_files = []\n",
        "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
        "            image_files.extend(Path(src_images_dir).glob(ext))\n",
        "        \n",
        "        print(f\"Found {len(image_files)} images in {split}\")\n",
        "        \n",
        "        if len(image_files) == 0:\n",
        "            print(f\"⚠️ No images found in {src_images_dir}\")\n",
        "            continue\n",
        "        \n",
        "        # First, copy original files\n",
        "        print(f\"Copying original {split} files...\")\n",
        "        copied_count = 0\n",
        "        for img_path in tqdm(image_files):\n",
        "            try:\n",
        "                # Copy image\n",
        "                dst_img = os.path.join(split_images_dir, img_path.name)\n",
        "                shutil.copy2(img_path, dst_img)\n",
        "                \n",
        "                # Copy label if exists\n",
        "                label_path = os.path.join(src_labels_dir, img_path.stem + '.txt')\n",
        "                if os.path.exists(label_path):\n",
        "                    dst_label = os.path.join(split_labels_dir, img_path.stem + '.txt')\n",
        "                    shutil.copy2(label_path, dst_label)\n",
        "                else:\n",
        "                    # Create empty label file\n",
        "                    dst_label = os.path.join(split_labels_dir, img_path.stem + '.txt')\n",
        "                    open(dst_label, 'w').close()\n",
        "                \n",
        "                copied_count += 1\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error copying {img_path}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        print(f\"✅ Copied {copied_count}/{len(image_files)} original files\")\n",
        "        \n",
        "        # Then create augmented versions (only for training set)\n",
        "        if split == 'train':\n",
        "            print(f\"Creating {num_augmentations} augmentations per training image...\")\n",
        "            augmented_count = 0\n",
        "            \n",
        "            for img_path in tqdm(image_files[:20]):  # Limit to first 100 for testing\n",
        "                try:\n",
        "                    label_path = os.path.join(src_labels_dir, img_path.stem + '.txt')\n",
        "                    augment_single_image(\n",
        "                        str(img_path), \n",
        "                        label_path, \n",
        "                        os.path.join(augmented_dataset_path, split),\n",
        "                        transform, \n",
        "                        num_augmentations\n",
        "                    )\n",
        "                    augmented_count += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"Error augmenting {img_path}: {e}\")\n",
        "                    continue\n",
        "            \n",
        "            print(f\"✅ Augmented {augmented_count} training images\")\n",
        "    \n",
        "    print(\"Dataset augmentation completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Defining data.yaml for augmented dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1754141404034
        }
      },
      "outputs": [],
      "source": [
        "def create_augmented_data_yaml(original_yaml_path, augmented_dataset_path, output_yaml_path):\n",
        "    \"\"\"\n",
        "    Create data.yaml file for augmented dataset\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read original yaml\n",
        "        with open(original_yaml_path, 'r') as f:\n",
        "            data = yaml.safe_load(f)\n",
        "        \n",
        "        # Update paths to use absolute paths\n",
        "        data['train'] = os.path.abspath(os.path.join(augmented_dataset_path, 'train', 'images'))\n",
        "        data['val'] = os.path.abspath(os.path.join(augmented_dataset_path, 'val', 'images'))\n",
        "        data['test'] = os.path.abspath(os.path.join(augmented_dataset_path, 'test', 'images'))\n",
        "        \n",
        "        # Ensure output directory exists\n",
        "        os.makedirs(os.path.dirname(output_yaml_path), exist_ok=True)\n",
        "        \n",
        "        # Save new yaml\n",
        "        with open(output_yaml_path, 'w') as f:\n",
        "            yaml.dump(data, f, default_flow_style=False)\n",
        "        \n",
        "        print(f\"✅ Created augmented data.yaml at: {output_yaml_path}\")\n",
        "        \n",
        "        # Verify the yaml file\n",
        "        with open(output_yaml_path, 'r') as f:\n",
        "            verify_data = yaml.safe_load(f)\n",
        "            print(f\"Verification - Train path: {verify_data.get('train', 'Not found')}\")\n",
        "            print(f\"Verification - Val path: {verify_data.get('val', 'Not found')}\")\n",
        "            print(f\"Verification - Test path: {verify_data.get('test', 'Not found')}\")\n",
        "        \n",
        "        return output_yaml_path\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error creating data.yaml: {e}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1754141407597
        }
      },
      "outputs": [],
      "source": [
        "def explore_current_directory():\n",
        "    \"\"\"\n",
        "    Explore current directory to help find dataset\n",
        "    \"\"\"\n",
        "    print(\"🔍 Exploring current directory structure...\")\n",
        "    current = os.getcwd()\n",
        "    print(f\"Current working directory: {current}\")\n",
        "    \n",
        "    # List current directory\n",
        "    print(\"\\nCurrent directory contents:\")\n",
        "    try:\n",
        "        for item in os.listdir(\".\"):\n",
        "            if os.path.isdir(item):\n",
        "                print(f\"  📁 {item}/\")\n",
        "                # Check if it looks like a dataset\n",
        "                if item.lower() in ['dataset', 'data', 'yolo', 'train', 'val', 'test']:\n",
        "                    print(f\"     → Potential dataset directory!\")\n",
        "            else:\n",
        "                print(f\"  📄 {item}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error listing directory: {e}\")\n",
        "    \n",
        "    # Check parent directory\n",
        "    print(\"\\nParent directory contents:\")\n",
        "    try:\n",
        "        for item in os.listdir(\"..\"):\n",
        "            if os.path.isdir(os.path.join(\"..\", item)):\n",
        "                print(f\"  📁 ../{item}/\")\n",
        "                if item.lower() in ['dataset', 'data', 'yolo']:\n",
        "                    print(f\"     → Potential dataset directory!\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error listing parent directory: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1754141410573
        }
      },
      "outputs": [],
      "source": [
        "def find_dataset_path():\n",
        "    \"\"\"\n",
        "    Find the actual dataset path in Azure ML\n",
        "    \"\"\"\n",
        "    print(\"🔍 Searching for dataset...\")\n",
        "    \n",
        "    # Common Azure ML dataset locations\n",
        "    possible_paths = [\n",
        "        \"./dataset\",               # <- your correct location\n",
        "        \"./dataset/data\",\n",
        "        \"../dataset\",\n",
        "        \"../dataset/data\",\n",
        "        \"/tmp/dataset\",\n",
        "        \"/home/azureuser/dataset\",\n",
        "    ]\n",
        "    \n",
        "    for path in possible_paths:\n",
        "        if os.path.exists(path):\n",
        "            print(f\"✅ Found dataset at: {path}\")\n",
        "            \n",
        "            # Check if it has proper YOLO structure\n",
        "            has_train = os.path.exists(os.path.join(path, 'train'))\n",
        "            has_val = os.path.exists(os.path.join(path, 'val'))\n",
        "            has_test = os.path.exists(os.path.join(path, 'test'))\n",
        "            has_yaml = os.path.exists(os.path.join(path, 'data.yaml'))\n",
        "            \n",
        "            print(f\"  📁 train/: {'✅' if has_train else '❌'}\")\n",
        "            print(f\"  📁 val/: {'✅' if has_val else '❌'}\")\n",
        "            print(f\"  📁 test/: {'✅' if has_test else '❌'}\")\n",
        "            print(f\"  📄 data.yaml: {'✅' if has_yaml else '❌'}\")\n",
        "            \n",
        "            if has_train and has_val and has_test and has_yaml:\n",
        "                return path\n",
        "            else:\n",
        "                print(f\"  ⚠️ Missing YOLO structure, continuing search...\")\n",
        "        else:\n",
        "            print(f\"❌ Not found: {path}\")\n",
        "    \n",
        "    print(\"❌ No valid dataset found!\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Train with albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754177215521
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔥 YOLO Smoke & Fire Detection with Albumentations (Azure ML) 🔥\n",
            "\n",
            "Testing write permissions...\n",
            "Testing write permissions in Azure ML...\n",
            "✅ /tmp - WRITABLE\n",
            "✅ /home/azureuser - WRITABLE\n",
            "✅ /home/azureuser - WRITABLE\n",
            "✅ . - WRITABLE\n",
            "✅ ./temp - WRITABLE\n",
            "\n",
            "Exploring directory structure...\n",
            "🔍 Exploring current directory structure...\n",
            "Current working directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/practica1/code/Users/practica/setdedate\n",
            "\n",
            "Current directory contents:\n",
            "  📄 .amlignore\n",
            "  📄 .amlignore.amltmp\n",
            "  📁 .ipynb_aml_checkpoints/\n",
            "  📄 albumentations.ipynb\n",
            "  📄 albumentations.ipynb.amltmp\n",
            "  📁 dataset/\n",
            "     → Potential dataset directory!\n",
            "  📄 dataset.py\n",
            "  📄 dataset.py.amltmp\n",
            "  📄 dataset.zip\n",
            "  📁 downloaded_dataset/\n",
            "  📁 fire-smoke-data-1/\n",
            "  📁 runs/\n",
            "  📁 runs_best_no_aug/\n",
            "  📄 runs_best_no_aug.zip\n",
            "  📁 smoke_fire_detect_dataset1-1/\n",
            "  📁 temp/\n",
            "  📄 test.ipynb\n",
            "  📄 test.ipynb.amltmp\n",
            "  📄 test1.py\n",
            "  📄 test1.py.amltmp\n",
            "  📄 test2.py\n",
            "  📄 test2.py.amltmp\n",
            "  📄 unzip_dataset.py\n",
            "  📄 unzip_dataset.py.amltmp\n",
            "  📄 unzip_runs_aug.py\n",
            "  📄 unzip_runs_aug.py.amltmp\n",
            "  📄 video_test.mp4\n",
            "  📄 yolov8n.pt\n",
            "  📄 yolov8s.pt\n",
            "\n",
            "Parent directory contents:\n",
            "  📁 ../setdedate/\n",
            "\n",
            "Testing Albumentations transforms...\n",
            "✅ Transform test successful!\n",
            "Input image shape: (480, 640, 3)\n",
            "Output image shape: (640, 640, 3)\n",
            "Input bboxes: [[0.5, 0.5, 0.2, 0.3], [0.3, 0.7, 0.1, 0.1]]\n",
            "Output bboxes: [[0.4999999850988388, 0.4999999850988388, 0.20000001788139343, 0.29999998211860657], [0.699999988079071, 0.699999988079071, 0.10000002384185791, 0.10000002384185791]]\n",
            "Labels preserved: [0.0, 1.0]\n",
            "\n",
            "==================================================\n",
            "Starting training pipeline...\n",
            "🔍 Searching for dataset...\n",
            "✅ Found dataset at: ./dataset\n",
            "  📁 train/: ❌\n",
            "  📁 val/: ❌\n",
            "  📁 test/: ❌\n",
            "  📄 data.yaml: ❌\n",
            "  ⚠️ Missing YOLO structure, continuing search...\n",
            "✅ Found dataset at: ./dataset/data\n",
            "  📁 train/: ✅\n",
            "  📁 val/: ✅\n",
            "  📁 test/: ✅\n",
            "  📄 data.yaml: ✅\n",
            "=== YOLO Training with Albumentations (Azure ML) ===\n",
            "✅ Found writable location: /tmp\n",
            "🔍 Searching for dataset...\n",
            "✅ Found dataset at: ./dataset\n",
            "  📁 train/: ❌\n",
            "  📁 val/: ❌\n",
            "  📁 test/: ❌\n",
            "  📄 data.yaml: ❌\n",
            "  ⚠️ Missing YOLO structure, continuing search...\n",
            "✅ Found dataset at: ./dataset/data\n",
            "  📁 train/: ✅\n",
            "  📁 val/: ✅\n",
            "  📁 test/: ✅\n",
            "  📄 data.yaml: ✅\n",
            "Original dataset: ./dataset/data\n",
            "Augmented dataset: /tmp/augmented_dataset\n",
            "Working directory: /tmp\n",
            "\n",
            "Step 1: Augmented dataset already exists, skipping...\n",
            "\n",
            "Step 2: Creating data.yaml for augmented dataset...\n",
            "✅ Created augmented data.yaml at: /tmp/augmented_dataset/data.yaml\n",
            "Verification - Train path: /tmp/augmented_dataset/train/images\n",
            "Verification - Val path: /tmp/augmented_dataset/val/images\n",
            "Verification - Test path: /tmp/augmented_dataset/test/images\n",
            "\n",
            "Step 3: Verifying dataset structure...\n",
            "✅ Training images: 14322\n",
            "✅ Validation images: 3099\n",
            "✅ Testing images: 4306\n",
            "\n",
            "Step 4: Training with Albumentations-augmented dataset...\n",
            "Loading model from: runs_best_no_aug/runs/detect/baseline_builtin2/weights/best.pt\n",
            "Using YAML file: /tmp/augmented_dataset/data.yaml\n",
            "names:\n",
            "- smoke\n",
            "- fire\n",
            "nc: 2\n",
            "path: /mnt/batch/tasks/shared/LS_root/mounts/clusters/computeextract/code/Users/practica/setdedate/dataset/data\n",
            "test: /tmp/augmented_dataset/test/images\n",
            "test_count: 4306\n",
            "train: /tmp/augmented_dataset/train/images\n",
            "train_count: 14122\n",
            "val: /tmp/augmented_dataset/val/images\n",
            "val_count: 3099\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.173 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.162 🚀 Python-3.10.18 torch-2.7.1+cu126 CPU (Intel Xeon Platinum 8272CL 2.60GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/tmp/augmented_dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=runs_best_no_aug/runs/detect/baseline_builtin2/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=albumentations_augmented5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/tmp/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/tmp/runs/albumentations_augmented5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2070.0±853.1 MB/s, size: 126.9 KB)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB02521.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB06626.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07199.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07271.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07278.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07297.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07305.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07312.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07534.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07538.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07540.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07541.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07543.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07552.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07554.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07555.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07556.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07557.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07559.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07562.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/augmented_dataset/train/images/WEB07639.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/tmp/augmented_dataset/val/images/WEB07535.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/tmp/augmented_dataset/val/images/WEB07536.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/tmp/augmented_dataset/val/images/WEB07539.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/tmp/augmented_dataset/val/images/WEB07542.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/tmp/augmented_dataset/val/images/WEB07561.jpg: corrupt JPEG restored and saved\n",
            "Plotting labels to /tmp/runs/albumentations_augmented5/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\n",
            "3 epochs completed in 9.774 hours.\n",
            "Optimizer stripped from /tmp/runs/albumentations_augmented5/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from /tmp/runs/albumentations_augmented5/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating /tmp/runs/albumentations_augmented5/weights/best.pt...\n",
            "Ultralytics 8.3.162 🚀 Python-3.10.18 torch-2.7.1+cu126 CPU (Intel Xeon Platinum 8272CL 2.60GHz)\n",
            "                   all       3099       3932      0.746      0.685      0.748      0.416\n",
            "                 smoke       1550       1756      0.799      0.723      0.799      0.466\n",
            "                  fire        879       2176      0.692      0.647      0.697      0.367\n",
            "Speed: 0.9ms preprocess, 140.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
            "Results saved to \u001b[1m/tmp/runs/albumentations_augmented5\u001b[0m\n",
            "✅ Albumentations training completed!\n",
            "Final Results:\n",
            "  mAP50: 0.7481545099942334\n",
            "  Precision: 0.7455572467065323\n",
            "  Recall: 0.6852536035624879\n",
            "✅ Results saved to: /tmp/training_results.json\n",
            "\n",
            "🎉 Training completed successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/3         0G       1.12     0.7755      1.164          2        640: 100%|██████████| 896/896 [3:00:34<00:00, 12.09s/it]  \n",
            "        2/3         0G      1.239      0.935      1.234          6        640: 100%|██████████| 896/896 [3:08:08<00:00, 12.60s/it]  s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  99%|█████████▉| 96/97 [08:04<00:06,  6.60s/it]\n",
            "        3/3         0G      1.206     0.8865      1.214          3        640: 100%|██████████| 896/896 [3:13:10<00:00, 12.94s/it]  \n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  99%|█████████▉| 96/97 [08:26<00:06,  6.89s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 97/97 [07:37<00:00,  4.72s/it]\n"
          ]
        }
      ],
      "source": [
        "def train_with_albumentations():\n",
        "    \"\"\"\n",
        "    Complete training pipeline with Albumentations for Azure ML\n",
        "    \"\"\"\n",
        "    print(\"=== YOLO Training with Albumentations (Azure ML) ===\")\n",
        "    \n",
        "    # Get writable location\n",
        "    writable_path = get_azure_writable_path()\n",
        "    \n",
        "    # Find the actual dataset location\n",
        "    original_dataset = find_dataset_path()\n",
        "    if not original_dataset:\n",
        "        print(\"❌ Cannot proceed without dataset!\")\n",
        "        return None\n",
        "    \n",
        "    original_yaml = os.path.join(original_dataset, \"data.yaml\")\n",
        "    \n",
        "    # New paths (writable location)\n",
        "    augmented_dataset = os.path.join(writable_path, \"augmented_dataset\")\n",
        "    augmented_yaml = os.path.join(augmented_dataset, \"data.yaml\")\n",
        "    \n",
        "    print(f\"Original dataset: {original_dataset}\")\n",
        "    print(f\"Augmented dataset: {augmented_dataset}\")\n",
        "    print(f\"Working directory: {writable_path}\")\n",
        "    \n",
        "    # Verify original dataset exists\n",
        "    if not os.path.exists(original_dataset):\n",
        "        print(f\"❌ Original dataset not found: {original_dataset}\")\n",
        "        return None\n",
        "    \n",
        "    if not os.path.exists(original_yaml):\n",
        "        print(f\"❌ Original data.yaml not found: {original_yaml}\")\n",
        "        return None\n",
        "    \n",
        "    # Step 1: Create augmented dataset\n",
        "    if not os.path.exists(augmented_dataset):\n",
        "        print(\"\\nStep 1: Creating augmented dataset...\")\n",
        "        try:\n",
        "            augment_dataset(original_dataset, augmented_dataset, num_augmentations=2)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to create augmented dataset: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"\\nStep 1: Augmented dataset already exists, skipping...\")\n",
        "    \n",
        "    # Step 2: Create data.yaml for augmented dataset\n",
        "    print(\"\\nStep 2: Creating data.yaml for augmented dataset...\")\n",
        "    try:\n",
        "        create_augmented_data_yaml(original_yaml, augmented_dataset, augmented_yaml)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to create data.yaml: {e}\")\n",
        "        return None\n",
        "    \n",
        "    # Step 3: Verify dataset structure\n",
        "    print(\"\\nStep 3: Verifying dataset structure...\")\n",
        "    train_images = os.path.join(augmented_dataset, 'train', 'images')\n",
        "    val_images = os.path.join(augmented_dataset, 'val', 'images')\n",
        "    test_images = os.path.join(augmented_dataset, 'test', 'images')\n",
        "    \n",
        "    if os.path.exists(train_images):\n",
        "        train_count = len(list(Path(train_images).glob('*.jpg')))\n",
        "        print(f\"✅ Training images: {train_count}\")\n",
        "    else:\n",
        "        print(f\"❌ Training images directory not found: {train_images}\")\n",
        "        return None\n",
        "    \n",
        "    if os.path.exists(val_images):\n",
        "        val_count = len(list(Path(val_images).glob('*.jpg')))\n",
        "        print(f\"✅ Validation images: {val_count}\")\n",
        "    else:\n",
        "        print(f\"❌ Validation images directory not found: {val_images}\")\n",
        "        return None\n",
        "\n",
        "    if os.path.exists(test_images):\n",
        "        test_count = len(list(Path(test_images).glob('*.jpg')))\n",
        "        print(f\"✅ Testing images: {test_count}\")\n",
        "    else:\n",
        "        print(f\"❌ Testing images directory not found: {test_images}\")\n",
        "        return None\n",
        "    \n",
        "    # Step 4: Train with Albumentations-augmented dataset\n",
        "    print(\"\\nStep 4: Training with Albumentations-augmented dataset...\")\n",
        "    \n",
        "    try:\n",
        "        # Load your pre-trained model\n",
        "        model_path = \"runs_best_no_aug/runs/detect/baseline_builtin2/weights/best.pt\" #modify with model's path\n",
        "        \n",
        "        if os.path.exists(model_path):\n",
        "            print(f\"Loading model from: {model_path}\")\n",
        "            albumentations_model = YOLO(model_path)\n",
        "        else:\n",
        "            print(\"Model path not found, using yolov8s.pt\")\n",
        "            albumentations_model = YOLO(\"yolov8s.pt\")\n",
        "        \n",
        "        print(f\"Using YAML file: {augmented_yaml}\")\n",
        "        with open(augmented_yaml) as f:\n",
        "            print(f.read())\n",
        "        \n",
        "        # Train the model\n",
        "        albumentations_results = albumentations_model.train(\n",
        "            data=augmented_yaml,\n",
        "            epochs=3,\n",
        "            batch=16,\n",
        "            augment=False,  # Disable built-in since we pre-augmented\n",
        "            patience=15,\n",
        "            workers=0,\n",
        "            device=\"cpu\",\n",
        "            name=\"albumentations_augmented\",\n",
        "            verbose=True,\n",
        "            project=os.path.join(writable_path, \"runs\")  # Save to writable location\n",
        "        )\n",
        "        \n",
        "        print(f\"✅ Albumentations training completed!\")\n",
        "        \n",
        "        # Extract results\n",
        "        if hasattr(albumentations_results, 'results_dict'):\n",
        "            map50 = albumentations_results.results_dict.get('metrics/mAP50(B)', 'N/A')\n",
        "            precision = albumentations_results.results_dict.get('metrics/precision(B)', 'N/A')\n",
        "            recall = albumentations_results.results_dict.get('metrics/recall(B)', 'N/A')\n",
        "            \n",
        "            print(f\"Final Results:\")\n",
        "            print(f\"  mAP50: {map50}\")\n",
        "            print(f\"  Precision: {precision}\")\n",
        "            print(f\"  Recall: {recall}\")\n",
        "        \n",
        "        # Save results summary\n",
        "        results_file = os.path.join(writable_path, \"training_results.json\")\n",
        "        results_summary = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'model_path': model_path,\n",
        "            'augmented_dataset': augmented_dataset,\n",
        "            'results': albumentations_results.results_dict if hasattr(albumentations_results, 'results_dict') else str(albumentations_results)\n",
        "        }\n",
        "        \n",
        "        with open(results_file, 'w') as f:\n",
        "            json.dump(results_summary, f, indent=2)\n",
        "        \n",
        "        print(f\"✅ Results saved to: {results_file}\")\n",
        "        \n",
        "        return albumentations_results\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Training failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def test_transforms():\n",
        "    \"\"\"\n",
        "    Test that transforms work correctly\n",
        "    \"\"\"\n",
        "    print(\"Testing Albumentations transforms...\")\n",
        "    \n",
        "    try:\n",
        "        transform = get_simple_transforms()\n",
        "        \n",
        "        # Create dummy data\n",
        "        dummy_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
        "        dummy_bboxes = [[0.5, 0.5, 0.2, 0.3], [0.3, 0.7, 0.1, 0.1]]  # YOLO format\n",
        "        dummy_labels = [0, 1]  # smoke, fire\n",
        "        \n",
        "        result = transform(\n",
        "            image=dummy_image, \n",
        "            bboxes=dummy_bboxes, \n",
        "            class_labels=dummy_labels\n",
        "        )\n",
        "        \n",
        "        print(\"✅ Transform test successful!\")\n",
        "        print(f\"Input image shape: {dummy_image.shape}\")\n",
        "        print(f\"Output image shape: {result['image'].shape}\")\n",
        "        print(f\"Input bboxes: {dummy_bboxes}\")\n",
        "        print(f\"Output bboxes: {result['bboxes']}\")\n",
        "        print(f\"Labels preserved: {result['class_labels']}\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Transform test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "def test_write_permissions():\n",
        "    \"\"\"\n",
        "    Test write permissions in different locations\n",
        "    \"\"\"\n",
        "    print(\"Testing write permissions in Azure ML...\")\n",
        "    \n",
        "    locations = [\n",
        "        \"/tmp\",\n",
        "        \"/home/azureuser\", \n",
        "        os.path.expanduser(\"~\"),\n",
        "        \".\",\n",
        "        \"./temp\"\n",
        "    ]\n",
        "    \n",
        "    for location in locations:\n",
        "        try:\n",
        "            test_dir = os.path.join(location, \"permission_test\")\n",
        "            os.makedirs(test_dir, exist_ok=True)\n",
        "            \n",
        "            test_file = os.path.join(test_dir, \"test.txt\")\n",
        "            with open(test_file, 'w') as f:\n",
        "                f.write(\"test write permission\")\n",
        "            \n",
        "            # Clean up\n",
        "            os.remove(test_file)\n",
        "            os.rmdir(test_dir)\n",
        "            \n",
        "            print(f\"✅ {location} - WRITABLE\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ {location} - NOT WRITABLE: {e}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🔥 YOLO Smoke & Fire Detection with Albumentations (Azure ML) 🔥\")\n",
        "    print()\n",
        "    \n",
        "    # Test permissions first\n",
        "    print(\"Testing write permissions...\")\n",
        "    test_write_permissions()\n",
        "    print()\n",
        "    \n",
        "    # Explore directory structure\n",
        "    print(\"Exploring directory structure...\")\n",
        "    explore_current_directory()\n",
        "    print()\n",
        "    \n",
        "    # Test transforms\n",
        "    if test_transforms():\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Starting training pipeline...\")\n",
        "        \n",
        "        # First, let's find the dataset\n",
        "        dataset_path = find_dataset_path()\n",
        "        if dataset_path:\n",
        "            # Run training pipeline\n",
        "            results = train_with_albumentations()\n",
        "            \n",
        "            if results:\n",
        "                print(\"\\n🎉 Training completed successfully!\")\n",
        "            else:\n",
        "                print(\"\\n❌ Training failed. Check the logs above.\")\n",
        "        else:\n",
        "            print(\"\\n❌ Cannot proceed without dataset. Please check your dataset location.\")\n",
        "    else:\n",
        "        print(\"❌ Fix transform issues before proceeding with training.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cp -r /tmp/augmented_dataset/data.yaml augmented_dataset2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cp -r /tmp/runs/albumentations_augmented5 runs_albumentations_augmented5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1754179909332
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📄 YAML Contents:\n",
            "names: ['smoke', 'fire']\n",
            "nc: 2\n",
            "path: /mnt/batch/tasks/shared/LS_root/mounts/clusters/computeextract/code/Users/practica/setdedate/dataset/data\n",
            "test: /tmp/augmented_dataset/test/images\n",
            "test_count: 4306\n",
            "train: /tmp/augmented_dataset/train/images\n",
            "train_count: 14122\n",
            "val: /tmp/augmented_dataset/val/images\n",
            "val_count: 3099\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "yaml_path = \"/tmp/augmented_dataset/data.yaml\"\n",
        "\n",
        "# Load and display YAML as a Python dict\n",
        "try:\n",
        "    with open(yaml_path, \"r\") as file:\n",
        "        data = yaml.safe_load(file)\n",
        "        print(\"📄 YAML Contents:\")\n",
        "        for key, value in data.items():\n",
        "            print(f\"{key}: {value}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ File not found: {yaml_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Error reading file: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
